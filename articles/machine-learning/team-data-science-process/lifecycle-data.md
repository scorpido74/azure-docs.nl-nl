---
title: Gegevens verwerving en inzichten van het proces voor gegevens Wetenschappen van teams
description: De doel stellingen, taken en producten voor het verwerving van gegevens en de fase van uw data-Science-projecten
services: machine-learning
author: marktab
manager: marktab
editor: marktab
ms.service: machine-learning
ms.subservice: team-data-science-process
ms.topic: article
ms.date: 01/10/2020
ms.author: tdsp
ms.custom: seodec18, previous-author=deguhath, previous-ms.author=deguhath
ms.openlocfilehash: 85d7159edb1bc8608165264578d77519bf09efc2
ms.sourcegitcommit: 1f48ad3c83467a6ffac4e23093ef288fea592eb5
ms.translationtype: MT
ms.contentlocale: nl-NL
ms.lasthandoff: 05/29/2020
ms.locfileid: "84195068"
---
# <a name="data-acquisition-and-understanding-stage-of-the-team-data-science-process"></a>Gegevens verwerving en uitleg van het team data Science process

In dit artikel vindt u een overzicht van de doelen, taken en producten die zijn gekoppeld aan de gegevens verwerving en de fase van het team data Science process (TDSP). Dit proces biedt een aanbevolen levens cyclus die u kunt gebruiken om uw projecten met een gegevens wetenschap te structureren. De levens cyclus bevat een overzicht van de belangrijkste fasen die door projecten meestal worden uitgevoerd, vaak iteratief:

   1. **Inzicht in het bedrijf**
   2. **Gegevens verzamelen en begrijpen**
   3. **Modellen maken**
   4. **Implementatie**
   5. **Aanvaarding van de klant**

Hier volgt een visuele representatie van de levens cyclus van TDSP: 

![TDSP levenscyclus](./media/lifecycle/tdsp-lifecycle2.png) 


## <a name="goals"></a>Doelstellingen
* Maak een schone en hoogwaardige gegevensset waarvan de relatie met de doel variabelen wordt begrepen. Zoek de gegevensset in de juiste analyse omgeving zodat u gereed bent om te model leren.
* Ontwikkel een oplossings architectuur van de gegevens pijplijn waarmee de gegevens regel matig worden vernieuwd en gescoord.

## <a name="how-to-do-it"></a>Hoe u dit doet
Er zijn drie hoofd taken die in deze fase worden behandeld:

   * **De gegevens** opnemen in de doel analyse omgeving.
   * **Verken de gegevens** om te bepalen of de gegevens kwaliteit voldoende is om de vraag te beantwoorden. 
   * **Stel een gegevens pijplijn** in om nieuwe of regel matig vernieuwde gegevens te beoordelen.

### <a name="ingest-the-data"></a>De gegevens opnemen
Stel het proces in om de gegevens van de bron locaties te verplaatsen naar de doel locaties waar u Analytics-bewerkingen uitvoert, zoals training en voor spellingen. Zie [gegevens laden in opslag omgevingen voor analyse](ingest-data.md)voor technische details en opties voor het verplaatsen van gegevens met verschillende Azure-gegevens Services. 

### <a name="explore-the-data"></a>De gegevens verkennen
Voordat u uw modellen traint, moet u een goed idee van de gegevens ontwikkelen. Real-World-gegevens sets zijn vaak ruis, ontbreken waarden of hebben een host van andere verschillen. U kunt gegevens samenvatting en visualisatie gebruiken om de kwaliteit van uw gegevens te controleren en de informatie die u nodig hebt voor het verwerken van de gegevens te verstrekken voordat deze klaar is voor model lering. Dit proces wordt vaak herhaald.

TDSP biedt een geautomatiseerd hulp programma met de naam [idee](https://github.com/Azure/Azure-TDSP-Utilities/blob/master/DataScienceUtilities/DataReport-Utils)om de gegevens te visualiseren en rapporten van gegevens overzichten voor te bereiden. We raden u aan eerst te beginnen met de idee om de gegevens te verkennen, zodat u de eerste gegevens interactief kunt ontwikkelen zonder code ring. Vervolgens kunt u aangepaste code schrijven voor het verkennen van gegevens en visualisaties. Zie [taken om gegevens voor te bereiden voor verbeterde machine learning](prepare-data.md)voor meer informatie over het opschonen van de gegevens.  

Nadat u tevreden bent met de kwaliteit van de gereinigde gegevens, is de volgende stap het beter inzicht te krijgen in de patronen die inherent zijn aan de gegevens. Deze gegevens analyse helpt u bij het kiezen en ontwikkelen van een geschikt voorspellend model voor uw doel. Zoek naar bewijs voor het goed verbonden met de gegevens met het doel. Bepaal vervolgens of er voldoende gegevens zijn om door te gaan met de volgende model stappen. Dit proces wordt vaak herhaald. Mogelijk moet u nieuwe gegevens bronnen met nauw keurigere of meer relevante gegevens vinden om de gegevensset die in de vorige fase is geïdentificeerd, te verbeteren. 

### <a name="set-up-a-data-pipeline"></a>Een gegevens pijplijn instellen
Naast de eerste opname en reiniging van de gegevens moet u doorgaans een proces instellen om nieuwe gegevens te scoren of de gegevens regel matig te vernieuwen als onderdeel van een doorlopend leer proces. Score kan worden voltooid met een gegevens pijplijn of werk stroom. Het [verplaatsen van gegevens van een SQL Server-exemplaar naar Azure SQL database met Azure Data Factory](move-sql-azure-adf.md) artikel geeft een voor beeld van het instellen van een pijp lijn met [Azure Data Factory](https://azure.microsoft.com/services/data-factory/). 

In deze fase ontwikkelt u een oplossings architectuur van de gegevens pijplijn. U ontwikkelt de pijp lijn parallel met de volgende fase van het data Science-project. Afhankelijk van de behoeften van uw bedrijf en de beperkingen van uw bestaande systemen waarin deze oplossing wordt geïntegreerd, kan de pijp lijn een van de volgende opties zijn: 

   * Op batch gebaseerd
   * Streaming of realtime 
   * Een hybride 

## <a name="artifacts"></a>Artifacts
Hieronder vindt u de producten in deze fase:

   * [Rapport gegevens kwaliteit](https://github.com/Azure/Azure-TDSP-ProjectTemplate/blob/master/Docs/Data_Report/DataSummaryReport.md): dit rapport bevat gegevens overzichten, de relaties tussen de verschillende kenmerken en doelen, de classificatie van variabelen en meer. Het hulp programma voor het [idee](https://github.com/Azure/Azure-TDSP-Utilities/blob/master/DataScienceUtilities/DataReport-Utils) dat is opgegeven als onderdeel van TDSP kan dit rapport snel genereren voor elke tabellaire gegevensset, zoals een CSV-bestand of een relationele tabel. 
   * **Oplossings architectuur**: de oplossings architectuur kan een diagram of beschrijving van uw gegevens pijplijn zijn die u gebruikt om scores of voor spellingen uit te voeren op nieuwe gegevens nadat u een model hebt gemaakt. Het bevat ook de pijp lijn voor het opnieuw trainen van uw model op basis van nieuwe gegevens. Sla het document op in de [projectmap](https://github.com/Azure/Azure-TDSP-ProjectTemplate/tree/master/Docs/Project) wanneer u de TDSP-sjabloon voor de directory structuur gebruikt.
   * **Beslissing van het controle punt**: voordat u begint met het bouwen van het ontwerp van de functie en het model, kunt u het project opnieuw evalueren om te bepalen of de verwachte waarde voldoende is om door te gaan. U kunt bijvoorbeeld klaar zijn om door te gaan, meer gegevens te verzamelen of het project te verlaten omdat de gegevens niet bestaan om de vraag te beantwoorden.

## <a name="next-steps"></a>Volgende stappen

Hier vindt u koppelingen naar elke stap in de levens cyclus van de TDSP:

   1. [Inzicht in het bedrijf](lifecycle-business-understanding.md)
   2. [Gegevens verzamelen en begrijpen](lifecycle-data.md)
   3. [Modellen maken](lifecycle-modeling.md)
   4. [Implementatie](lifecycle-deployment.md)
   5. [Aanvaarding van de klant](lifecycle-acceptance.md)

We bieden volledige instructies voor het demonstreren van alle stappen in het proces voor specifieke scenario's. Het artikel [voorbeeld](walkthroughs.md) scenario's bevat een lijst met de scenario's met koppelingen en miniaturen. In de scenario's wordt uitgelegd hoe u Cloud, on-premises hulpprogram ma's en services in een werk stroom of pijp lijn kunt combi neren om een intelligente toepassing te maken. 

Zie [de TDSP gebruiken met Azure machine learning](https://docs.microsoft.com/azure/machine-learning/team-data-science-process/lifecycle-data)voor voor beelden van het uitvoeren van stappen in TDSPs die gebruikmaken van Azure machine learning Studio.
